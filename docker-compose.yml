version: "3.9"

services:
  # PostgreSQL
  postgres:
    image: postgres:17
    container_name: postgres_container
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    command: postgres -c 'listen_addresses=*' -c 'password_encryption=md5'
    ports:
      - "15432:${POSTGRES_PORT}"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  metastore-db:
    image: postgres:14
    container_name: hive-metastore-db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore
    volumes:
      - metastore-db-data:/var/lib/postgresql/data
    networks:
      - app_network

  # AIRFLOW POSTGRES (metadata)
  airflow-postgres:
    image: postgres:14
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-postgres-data:/var/lib/postgresql/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - SERVICE_OPTS=-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://metastore-db:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive
    ports:
      - "9083:9083"
    volumes:
      - warehouse:/opt/hive/data/warehouse
      - ./drivers/postgresql-42.7.7.jar:/opt/hive/lib/postgresql.jar
    depends_on:
      - metastore-db
    networks:
      - app_network

  hive-server:
    image: apache/hive:4.0.0
    container_name: hive-server2
    environment:
      - SERVICE_NAME=hiveserver2
      - SERVICE_OPTS=-Dhive.metastore.uris=thrift://hive-metastore:9083
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - warehouse:/opt/hive/data/warehouse  # ¡AGREGAR ESTE VOLUMEN!
    depends_on:
      - hive-metastore
    networks:
      - app_network
  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - warehouse:/opt/bitnami/spark/warehouse
    networks:
      - app_network
    depends_on:
      - hive-metastore

  # AIRFLOW SCHEDULER
  airflow-scheduler:
    build: ./airflow
    container_name: airflow_scheduler
    profiles:
      - airflow
    command: >
      bash -c "
        echo 'Esperando a que el webserver inicialice la DB...' &&
        sleep 30 &&
        airflow scheduler
      "
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    depends_on:
      airflow-postgres:
        condition: service_healthy
    networks:
      - app_network

  # AIRFLOW WEBSERVER
  airflow-webserver:
    build: ./airflow
    container_name: airflow_webserver
    profiles:
      - airflow
    command: >
      bash -c "
        airflow db migrate && 
        sleep 15 &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
        airflow webserver
      "
    ports:
      - "8082:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    depends_on:
      airflow-postgres:
        condition: service_healthy
    networks:
      - app_network

  # REDIS (CACHÉ VOLÁTIL)
  redis:
    image: redis:7.2
    container_name: redis
    ports:
      - "${REDIS_PORT}:${REDIS_PORT}"
    networks:
      - app_network

  # Elastic Search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      - "${ELASTIC_PORT}:${ELASTIC_PORT}"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    networks:
      - app_network

  # Neo4J
  neo4j:
    image: neo4j:latest
    container_name: neo4j
    environment:
      - NEO4J_AUTH=${NEO4J_USER}/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc"]
    ports:
      - "${NEO4J_HTTP_PORT}:7474"  # Browser web
      - "${NEO4J_PORT}:7687"       # Bolt protocol
    volumes:
      - neo4j_data:/data
    networks:
      - app_network

  # AUTH SERVICE - INSTANCIA 1
  auth_service1:
    build: ./auth_service
    container_name: auth_service1
    profiles:
      - backend
      - test
    restart: always
    ports:
      - "${AUTH_PORT}:${AUTH_PORT}"
    depends_on:
      - postgres
      - mongos1
    environment:
      API_URL: ${API_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      AUTH_PORT: ${AUTH_PORT}
      JWT_SECRET: ${JWT_SECRET}
    networks:
      - app_network

  # AUTH SERVICE - INSTANCIA 2
  auth_service2:
    build: ./auth_service
    container_name: auth_service2
    profiles:
      - backend
      - test
    restart: always
    expose:
      - "${AUTH_PORT}"
    depends_on:
      - postgres
      - mongos1
    environment:
      API_URL: ${API_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      AUTH_PORT: ${AUTH_PORT}
      JWT_SECRET: ${JWT_SECRET}
    networks:
      - app_network

  auth_test:
    build:
      context: ./auth_service
      dockerfile: dockerfile.test
    container_name: auth_service_test_container
    profiles:
      - test
    depends_on:
      - postgres
      - mongos1
    environment:
      API_URL: ${API_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      AUTH_PORT: ${AUTH_PORT}
      JWT_SECRET: ${JWT_SECRET}
    networks:
      - app_network

  # API SERVICE - INSTANCIA 1
  api1:
    build: ./api
    container_name: api1
    profiles:
      - backend
      - test
    restart: always
    ports:
      - "${API_PORT}:${API_PORT}"
    depends_on:
      - auth_service1
      - postgres
      - mongos1
    environment:
      AUTH_SERVICE_URL: ${AUTH_SERVICE_URL}
      SEARCH_SERVICE_URL: ${SEARCH_SERVICE_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      API_PORT: ${API_PORT}
    networks:
      - app_network

  # API SERVICE - INSTANCIA 2
  api2:
    build: ./api
    container_name: api2
    profiles:
      - backend
      - test
    restart: always
    expose:
      - "${API_PORT}"
    depends_on:
      - auth_service1
      - postgres
      - mongos1
    environment:
      AUTH_SERVICE_URL: ${AUTH_SERVICE_URL}
      SEARCH_SERVICE_URL: ${SEARCH_SERVICE_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      API_PORT: ${API_PORT}
    networks:
      - app_network

  api_test:
    build:
      context: ./api
      dockerfile: dockerfile.test
    container_name: api_service_test_container
    profiles:
      - test
    depends_on:
      - postgres
      - mongos1
    environment:
      AUTH_SERVICE_URL: ${AUTH_SERVICE_URL}
      SEARCH_SERVICE_URL: ${SEARCH_SERVICE_URL}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_HOST: ${REDIS_HOST}
      DB_TYPE: ${DB_TYPE}
      MONGO_URI: ${MONGO_URI}
      DB_HOST: ${POSTGRES_HOST}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_PORT: ${POSTGRES_PORT}
      API_PORT: ${API_PORT}
    networks:
      - app_network

  # SEARCH SERVICE - INSTANCIA 1
  search_service1:
    build: ./search_service
    container_name: search_service1
    profiles:
      - backend
      - test
    restart: always
    ports:
      - "${SEARCH_PORT}:${SEARCH_PORT}"
    depends_on:
      - auth_service1
      - api1
      - elasticsearch
      - redis
    environment:
      - API_URL=${API_URL}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - ELASTIC_NODE=${ELASTIC_NODE}
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_HOST=${REDIS_HOST}
      - SEARCH_PORT=${SEARCH_PORT}
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - app_network

  # SEARCH SERVICE - INSTANCIA 2
  search_service2:
    build: ./search_service
    container_name: search_service2
    profiles:
      - backend
      - test
    restart: always
    expose:
      - "${SEARCH_PORT}"
    depends_on:
      - auth_service1
      - api1
      - elasticsearch
      - redis
    environment:
      - API_URL=${API_URL}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - ELASTIC_NODE=${ELASTIC_NODE}
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_HOST=${REDIS_HOST}
      - SEARCH_PORT=${SEARCH_PORT}
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - app_network

  search_test:
    build:
      context: ./search_service
      dockerfile: dockerfile.test
    container_name: search_service_test_container
    profiles:
      - test
    depends_on:
      - elasticsearch
      - redis
    environment:
      - API_URL=${API_URL}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - ELASTIC_NODE=${ELASTIC_NODE}
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_HOST=${REDIS_HOST}
      - SEARCH_PORT=${SEARCH_PORT}
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - app_network

  # GRAPH SERVICE - INSTANCIA 1
  graph_service1:
    build: ./graph_service
    container_name: graph_service1
    profiles:
      - backend
    restart: always
    ports:
      - "${GRAPH_PORT}:${GRAPH_PORT}"
    depends_on:
      - auth_service1
      - api1
      - neo4j
      - redis
    environment:
      - API_URL=${API_URL}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_HOST=${REDIS_HOST}
      - DB_TYPE=${DB_TYPE}
      - GRAPH_PORT=${GRAPH_PORT}
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - app_network

  # GRAPH SERVICE - INSTANCIA 2
  graph_service2:
    build: ./graph_service
    container_name: graph_service2
    profiles:
      - backend
    restart: always
    expose:
      - "${GRAPH_PORT}"
    depends_on:
      - auth_service1
      - api1
      - neo4j
      - redis
    environment:
      - API_URL=${API_URL}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_HOST=${REDIS_HOST}
      - DB_TYPE=${DB_TYPE}
      - GRAPH_PORT=${GRAPH_PORT}
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - app_network

  etl_service:
      build:
        context: ./etl_service
      container_name: etl_service
      volumes:
        - warehouse:/opt/hive/data/warehouse
      depends_on:
        - hive-metastore
        - metastore-db
        - postgres
        - mongos1
      profiles:
        - etl
      environment:
        - POSTGRES_HOST=${POSTGRES_HOST}
        - POSTGRES_USER=${POSTGRES_USER}
        - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
        - POSTGRES_DB=${POSTGRES_DB}
        - POSTGRES_PORT=${POSTGRES_PORT}
        - MONGO_URI=${MONGO_URI}
      networks:
        - app_network  

  # ANALYTICS SERVER
  analytics_service:
    build:
      context: ./analytics_service
    container_name: analytics_service
    ports:
      - "8501:8501"  # Puerto por defecto de Streamlit
    volumes:
      - warehouse:/opt/hive/data/warehouse
    environment:
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
    depends_on:
      - hive-metastore
      - metastore-db
      - neo4j
    profiles:
      - analytics
    networks:
      - app_network

  spark_analytics:
      build:
        context: ./spark_analytics
      container_name: spark_analytics
      volumes:
        - warehouse:/opt/hive/data/warehouse
      depends_on:
        - hive-metastore
        - metastore-db
      profiles:
        - analytics
      networks:
        - app_network

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin_container
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "${PGADMIN_PORT}:80"
    depends_on:
      - postgres
    networks:
      - app_network

  # Config Servers MongoDB
  mongocfg1:
    image: mongo:6.0.6
    container_name: mongocfg1
    command: mongod --configsvr --replSet configReplSet --port 27017 --bind_ip_all
    volumes:
      - mongocfg1-data:/data/db
    networks:
      - app_network

  mongocfg2:
    image: mongo:6.0.6
    container_name: mongocfg2
    command: mongod --configsvr --replSet configReplSet --port 27017 --bind_ip_all
    volumes:
      - mongocfg2-data:/data/db
    networks:
      - app_network

  mongocfg3:
    image: mongo:6.0.6
    container_name: mongocfg3
    command: mongod --configsvr --replSet configReplSet --port 27017 --bind_ip_all
    volumes:
      - mongocfg3-data:/data/db
    networks:
      - app_network

  # Primer Shard ReplicaSet
  mongors1n1:
    image: mongo:6.0.6
    container_name: mongors1n1
    command: mongod --shardsvr --replSet shard1ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors1n1-data:/data/db
    networks:
      - app_network

  mongors1n2:
    image: mongo:6.0.6
    container_name: mongors1n2
    command: mongod --shardsvr --replSet shard1ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors1n2-data:/data/db
    networks:
      - app_network

  mongors1n3:
    image: mongo:6.0.6
    container_name: mongors1n3
    command: mongod --shardsvr --replSet shard1ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors1n3-data:/data/db
    networks:
      - app_network

  # Segundo Shard ReplicaSet
  mongors2n1:
    image: mongo:6.0.6
    container_name: mongors2n1
    command: mongod --shardsvr --replSet shard2ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors2n1-data:/data/db
    networks:
      - app_network

  mongors2n2:
    image: mongo:6.0.6
    container_name: mongors2n2
    command: mongod --shardsvr --replSet shard2ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors2n2-data:/data/db
    networks:
      - app_network

  mongors2n3:
    image: mongo:6.0.6
    container_name: mongors2n3
    command: mongod --shardsvr --replSet shard2ReplSet --port 27017 --bind_ip_all
    volumes:
      - mongors2n3-data:/data/db
    networks:
      - app_network

  # Mongos Router
  mongos1:
    image: mongo:6.0.6
    container_name: mongos1
    ports:
      - "27019:27017"
    depends_on:
      - mongocfg1
      - mongocfg2
      - mongocfg3
      - mongors1n1
      - mongors1n2
      - mongors1n3
    command: mongos --configdb configReplSet/mongocfg1:27017,mongocfg2:27017,mongocfg3:27017 --port 27017 --bind_ip_all
    networks:
      - app_network

  mongos2:
    image: mongo:6.0.6
    container_name: mongos2
    ports:
      - "27029:27017"
    depends_on:
      - mongocfg1
      - mongocfg2
      - mongocfg3
      - mongors1n1
      - mongors1n2
      - mongors1n3
    command: mongos --configdb configReplSet/mongocfg1:27017,mongocfg2:27017,mongocfg3:27017 --port 27017 --bind_ip_all
    networks:
      - app_network

  mongos3:
    image: mongo:6.0.6
    container_name: mongos3
    ports:
      - "27039:27017"
    depends_on:
      - mongocfg1
      - mongocfg2
      - mongocfg3
      - mongors1n1
      - mongors1n2
      - mongors1n3
    command: mongos --configdb configReplSet/mongocfg1:27017,mongocfg2:27017,mongocfg3:27017 --port 27017 --bind_ip_all
    networks:
      - app_network

  # Mongo Express (admin web para Mongo)
  mongo-express:
    image: mongo-express
    container_name: mongo_express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGOSRV: "false"
      ME_CONFIG_MONGODB_SERVER: mongos1
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_BASICAUTH_USERNAME: ${MONGO_EXPRESS_USER}
      ME_CONFIG_BASICAUTH_PASSWORD: ${MONGO_EXPRESS_PASS}
    depends_on:
      - mongos1
    networks:
      - app_network

  # Kibana (para gestionar ElasticSearch)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.6.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=${ELASTIC_NODE}
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - app_network

  # Load Balancer
  nginx:
    image: nginx:latest
    container_name: nginx_load_balancer
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api1
      - api2
      - search_service1
      - search_service2
      - auth_service1
      - auth_service2
    networks:
      - app_network
    profiles:
      - backend

volumes:
  postgres_data:
  mongocfg1-data:
  mongocfg2-data:
  mongocfg3-data:
  mongors1n1-data:
  mongors1n2-data:
  mongors1n3-data:
  mongors2n1-data:
  mongors2n2-data:
  mongors2n3-data:
  elastic_data:
  neo4j_data:
  metastore-db-data:
  warehouse:
  airflow-postgres-data:

networks:
  app_network: